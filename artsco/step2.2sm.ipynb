{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Sent Environment Variables\n",
    "print(\"Environment variables set successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/groups/jamesz/batu/TextualFeedback\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/groups/jamesz/batu/miniconda3/envs/hfds-py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratch/groups/jamesz/batu/TextualFeedback/artsco/voter/voters.py:70: SyntaxWarning: invalid escape sequence '\\%'\n",
      "  \"I know you've been looking for a tool that seamlessly integrates into your current workflow without disruption. That's why we designed our product to be plug-and-play, delivering immediate value from day one. One of our clients in your industry reduced operational costs by 23\\% in just three months—without adding extra staff or hours. We're here to make your work easier, faster, and more rewarding, so your customers notice the difference immediately.\",\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from transformers import  AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "# from artsco.utils import process_dataset, MODELS, apply_chat_template\n",
    "\n",
    "from artsco.voter.voters import Voters\n",
    "from artsco.voter.utils import load_persona100\n",
    "\n",
    "# CURRENT_MODELS = [\"Qwen/Qwen3-8B\",  \"meta-llama/Llama-3.1-8B-Instruct\", \"Qwen/Qwen3-14B\"]\n",
    "QWEN_MODEL_NAMES = [\"Qwen/Qwen3-8B\"] #, \"Qwen/Qwen3-32B\"]\n",
    "LLAMA_MODEL_NAMES = [\"meta-llama/Llama-3.1-8B-Instruct\"] #, \"meta-llama/Llama-3.1-70B-Instruct\"]\n",
    "OPENAI_MODEL_NAMES = [\"openai/gpt-oss-20b\"]\n",
    "MODELS = QWEN_MODEL_NAMES + LLAMA_MODEL_NAMES \n",
    "TASKS = [\"task_elections\", \"task_sales\" , \"task_sm\"]\n",
    "SPLITS = [\"train\"]\n",
    "METHODS =[\"base\", \"rft\", \"tfb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Second Stage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [\"task_elections\", \"task_sales\" , \"task_sm\"]\n",
    "\n",
    "results_path_root = \"artsco/res\"\n",
    "split = \"test\"\n",
    "datasets = {task: {model: {method: load_dataset(\"json\", data_files=os.path.join(results_path_root,  task, model, method, f\"{split}_step2.json\"))['train'] for method in METHODS} for model in MODELS} for task in TASKS} \n",
    "\n",
    "num_voters = 20\n",
    "bios = load_persona100()[:num_voters]\n",
    "\n",
    "# voter_votes, voter_thinks = voters.get_votes_list(player_candidates)\n",
    "\n",
    "\n",
    "all_candidates0 = {task: {model: {method: [] for method in METHODS} for model in MODELS} for task in TASKS} \n",
    "all_candidates1 = {task: {model: {method: [] for method in METHODS} for model in MODELS} for task in TASKS} \n",
    "\n",
    "TASK = [\"task_elections\", \"task_sales\" , \"task_sm\"]\n",
    "TASK = \"task_sm\"\n",
    "TASKS = [TASK]\n",
    "for task in TASKS:\n",
    "    # voters = Voters(bios=bios, task=task, model_name= \"gpt-4o-mini\")\n",
    "    for model in MODELS:\n",
    "        for method in METHODS:\n",
    "            ds = datasets[task][model][method]\n",
    "            cands = ds[\"player_candidates\"]\n",
    "            cands0 = [c[0] for c in cands]\n",
    "            cands1 = [c[1] for c in cands]\n",
    "\n",
    "            all_candidates0[task][model][method] = cands0\n",
    "            all_candidates1[task][model][method] = cands1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting votes:   0%|          | 0/20480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting votes: 100%|██████████| 20480/20480 [23:43<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('base', 'rft') Mean: 0.523681640625 Std: 0.21871298841988865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting votes: 100%|██████████| 20480/20480 [28:20<00:00, 12.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('base', 'tfb') Mean: 0.556962890625 Std: 0.23916410134653213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting votes: 100%|██████████| 20480/20480 [26:38<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('rft', 'tfb') Mean: 0.5416406250000001 Std: 0.2526674950149096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting votes: 100%|██████████| 20480/20480 [28:23<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('base', 'rft') Mean: 0.5509765625 Std: 0.31097129753111236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting votes: 100%|██████████| 20480/20480 [24:08<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('base', 'tfb') Mean: 0.558349609375 Std: 0.30990502394610336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting votes: 100%|██████████| 20480/20480 [24:52<00:00, 13.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('rft', 'tfb') Mean: 0.5028320312499999 Std: 0.3178707037247991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "voters = Voters(bios=bios, task=task, model_name= \"gpt-4o-mini\")\n",
    "\n",
    "METHOD_PAIRS =[ (\"base\", \"rft\"),  (\"base\", \"tfb\"),  (\"rft\", \"tfb\")]\n",
    "# how superior is the second over the first\n",
    "# 0.5 menas equal, 0.9 menas the second is better, 0.1 menas the first is better\n",
    "# we want to see >0.5\n",
    "\n",
    "# means =  \n",
    "# stds = \n",
    "results = {}\n",
    "results_std = {}\n",
    "for task in TASKS:\n",
    "    results[task] = {}\n",
    "    results_std[task] = {}\n",
    "\n",
    "    voters = Voters(bios=bios, task=task, model_name= \"gpt-4o-mini\")\n",
    "    for model in MODELS:\n",
    "        results[task][model] = {}\n",
    "        results_std[task][model] = {}\n",
    "        for pair in METHOD_PAIRS:\n",
    "            player_candidates = list(zip(all_candidates0[task][model][pair[0]], all_candidates0[task][model][pair[1]]))[:]\n",
    "\n",
    "            voter_votes, voter_thinks, voter_choices = voters.get_votes_list(player_candidates)\n",
    "            mean = np.mean([np.round((Counter(v)[1] / (Counter(v)[1] + Counter(v)[0])), 2).item() for v in voter_votes])\n",
    "            std = np.std([np.round((Counter(v)[1] / (Counter(v)[1] + Counter(v)[0])), 2).item() for v in voter_votes])\n",
    "            \n",
    "            results[task][model][\"-\".join(pair)] = mean\n",
    "            results_std[task][model][\"-\".join(pair)] = std\n",
    "            print(pair, \"Mean:\", mean, \"Std:\", std)\n",
    "\n",
    "import json\n",
    "json_path = f'artsco/res/{TASK}_final.json'\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump({\"mean\": results, \"std\": results_std}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
