{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Sent Environment Variables\n",
    "print(\"Environment variables set successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from transformers import  AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils import process_dataset, MODELS, apply_chat_template\n",
    "\n",
    "# CURRENT_MODELS = [\"Qwen/Qwen3-8B\",  \"meta-llama/Llama-3.1-8B-Instruct\", \"Qwen/Qwen3-14B\"]\n",
    "QWEN_MODEL_NAMES = [\"Qwen/Qwen3-8B\"] #, \"Qwen/Qwen3-32B\"]\n",
    "LLAMA_MODEL_NAMES = [\"meta-llama/Llama-3.1-8B-Instruct\"] #, \"meta-llama/Llama-3.1-70B-Instruct\"]\n",
    "MODELS = QWEN_MODEL_NAMES + LLAMA_MODEL_NAMES \n",
    "TASKS = [\"task_elections\", \"task_sales\" , \"task_sm\"]\n",
    "TASKS = [ \"task_elections\",]\n",
    "SPLITS = [\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Second Stage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_names = [\"task_elections\", \"task_sales\" , \"task_sm\"]\n",
    "splits = [\"train\" , \"test\"]\n",
    "\n",
    "datasets = {ds_name: {split: load_dataset(\"json\", data_files=f\"data/{ds_name}/{split}.json\")['train'] for split in splits} for ds_name in ds_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rft(dataset):\n",
    "    rft_dataset = []\n",
    "    for idx in range(len(dataset)):\n",
    "        curr_votes = dataset[idx][\"voter_votes\"]\n",
    "        vote_count = Counter(curr_votes)\n",
    "        vote_count_diff = vote_count[0] - vote_count[1]\n",
    "        if vote_count_diff > 0:\n",
    "            filtered_entry = {k: v[0] for k, v in dataset[idx].items() if k in ['prompt', 'completion']}\n",
    "        elif vote_count_diff < 0:\n",
    "            filtered_entry = {k: v[1] for k, v in dataset[idx].items() if k in ['prompt', 'completion']}\n",
    "        else:\n",
    "            pass\n",
    "        rft_dataset.append(filtered_entry)\n",
    "    return rft_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_INSTRUCTION_THINK = (\n",
    "    \"You are a helpful assistant. \"\n",
    "    \"When you reply, enclose your thoughts inside <think> â€¦ </think>. Do not output anything else.\"\n",
    ")\n",
    "\n",
    "# Task Prompts\n",
    "def process_task_elections(s, candidates, tokenizer):\n",
    "    candidate_webname = s[\"candidate_webname\"]\n",
    "    cand_party = s[\"cand_party\"] # not used\n",
    "    biography_text = s[\"biography_text\"]\n",
    "\n",
    "    candidates_content = \"\\n\\n\".join([ f\"## Option {idx+1} (A or B): {c.strip()}\"  for idx , c in enumerate(candidates)])\n",
    "\n",
    "    prompt_content = (\n",
    "        \"# Instructions\\n\"\n",
    "        \"Carefully review the candidate profile and the candidate's campaign statements.\"\n",
    "        \"You are participating in an online election and you read the two campaign statements.\"\n",
    "        \"You will eventually choose one of them.\"\n",
    "        \"Considering your character, express your thoughts about the campaign statements.\\n\\n\"\n",
    "        f\"# Candidate Name\\n{candidate_webname}\\n\\n\"\n",
    "        f\"# Candidate Bio\\n{biography_text}\\n\\n\"\n",
    "        f\"# Campaign Statements\\n{candidates_content}\\n\\n\"\n",
    "        f\"# Formatting Instructions\\n{XML_INSTRUCTION_THINK}\\n\"\n",
    "    )\n",
    "    return apply_chat_template(tokenizer, prompt_content)\n",
    "\n",
    "def process_task_sales(s, candidates, tokenizer):\n",
    "    categories = s[\"categories\"]\n",
    "    title = s[\"title\"]\n",
    "    description = s[\"description\"]\n",
    "\n",
    "    candidates_content = \"\\n\\n\".join([ f\"## Option {idx+1} (A or B): {c.strip()}\"  for idx , c in enumerate(candidates)])\n",
    "\n",
    "    prompt_content = (\n",
    "        \"# Instructions\\n\"\n",
    "        \"Carefully review the product information and the product's sales pitches.\" \n",
    "        \"You are shopping at an online store and come across the two sales pitches. \"\n",
    "        \"You will eventually choose one of them.\"\n",
    "        \"Considering your character, express your thoughts about the sales pitches.\\n\\n\"\n",
    "        f\"# Product Title\\n{title}\\n\\n\"\n",
    "        f\"# Product Categories\\n{\", \".join(categories)}\\n\\n\"\n",
    "        f\"# Product Description\\n{description}\\n\\n\"\n",
    "        f\"# Sales Pitches\\n{candidates_content}\\n\\n\"\n",
    "        f\"# Formatting Instructions\\n{XML_INSTRUCTION_THINK}\\n\"\n",
    "    )\n",
    "    return apply_chat_template(tokenizer, prompt_content)\n",
    "\n",
    "def process_task_sm(s, candidates, tokenizer):\n",
    "    article = s[\"article\"]\n",
    "\n",
    "    candidates_content = \"\\n\\n\".join([ f\"## Option {idx+1} (A or B): {c.strip()}\"  for idx , c in enumerate(candidates)])\n",
    "\n",
    "    prompt_content = (\n",
    "        \"# Instructions\\n\"\n",
    "        \"Carefully review the news article and the social media posts related to the article.\"\n",
    "        \"You are scrolling through your social media feed and see the two posts. \"\n",
    "        \"You will eventually choose one of them.\"\n",
    "        \"Considering your character, express your thoughts about the social media posts.\\n\\n\"\n",
    "        f\"# Article\\n{article}\\n\\n\"\n",
    "        f\"# Social Media Posts\\n{candidates_content}\\n\\n\"\n",
    "        f\"# Formatting Instructions\\n{XML_INSTRUCTION_THINK}\\n\"\n",
    "    )\n",
    "    return apply_chat_template(tokenizer, prompt_content)\n",
    "\n",
    "def process_candidates(s, candidates, tokenizer, task):\n",
    "    if task == \"task_elections\":\n",
    "        return process_task_elections(s, candidates, tokenizer)\n",
    "    elif task == \"task_sales\":\n",
    "        return process_task_sales(s, candidates, tokenizer)\n",
    "    elif task == \"task_sm\":\n",
    "        return process_task_sm(s, candidates, tokenizer)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Dataset processing not implemented for: {task}\")\n",
    "\n",
    "\n",
    "def get_tfb(dataset, dataset_base, Tokenizer, task):\n",
    "    tfb_data = []\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        curr_candidates = dataset[idx][\"player_candidates\"] # feature\n",
    "        curr_thinks = dataset[idx][\"voter_thinks\"] # target\n",
    "        \n",
    "        example = dataset_base[idx]\n",
    "        prompt = process_candidates(example, curr_candidates, Tokenizer, task)\n",
    "\n",
    "        completions =  [f\"<think> {think.strip()} </think>\" for think in curr_thinks if think]\n",
    "        for completion in completions:\n",
    "            tfb_data.append({\"prompt\": prompt, \"completion\": completion})\n",
    "    \n",
    "    return tfb_data\n",
    "\n",
    "# In comparing these two options, what is a potential response a user can give?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_names = [\"task_elections\", \"task_sales\" , \"task_sm\"] \n",
    "splits = [\"train\" , \"test\"]\n",
    "\n",
    "# datasets = {ds_name: {split: load_dataset(\"json\", data_files=f\"data/{ds_name}/{split}.json\")['train'] for split in splits} for ds_name in ds_names}\n",
    "# from utils2 import get_rft, get_tfb\n",
    "\n",
    "results_path_root = \"data\"\n",
    "ds_paths = {}\n",
    "\n",
    "for task in TASKS:\n",
    "    for split in SPLITS:\n",
    "        for model_name in MODELS:\n",
    "            results_path  = os.path.join(results_path_root,  task, model_name,  f\"{split}_step1.json\")\n",
    "            dataset = load_dataset(\"json\", data_files=results_path)[\"train\"]\n",
    "            Tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "            dataset_base = datasets[task][split]\n",
    "\n",
    "            ### RFT ###\n",
    "            rft_ds_list = get_rft(dataset)\n",
    "            rft_ds_list = rft_ds_list * 3\n",
    "            random.shuffle(rft_ds_list)\n",
    "            rft_ds = Dataset.from_list(rft_ds_list)\n",
    "\n",
    "            rft_path  = os.path.join(results_path_root,  task, model_name,  f\"{split}_rft.json\")\n",
    "            if os.path.exists(rft_path):\n",
    "                os.remove(rft_path)\n",
    "            rft_ds.to_json(rft_path)\n",
    "\n",
    "            ### TFB ###\n",
    "            tfb_ds = get_tfb(dataset, dataset_base, Tokenizer, task=task)\n",
    "            random.shuffle(tfb_ds)\n",
    "            tfb_ds = tfb_ds[:len(rft_ds_list)] + rft_ds_list\n",
    "            tfb_ds = Dataset.from_list(tfb_ds)\n",
    "\n",
    "            tfb_path  = os.path.join(results_path_root,  task, model_name,  f\"{split}_tfb.json\")\n",
    "            if os.path.exists(tfb_path):\n",
    "                os.remove(tfb_path)\n",
    "            tfb_ds.to_json(tfb_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
